{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a300d6bb-fa7d-4e8a-bb92-41ea035041c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import ElectraModel, ElectraTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cdb0f9c-a533-49a6-b4ad-74c08ba9c3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['electra.embeddings.position_ids']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = ElectraModel.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e34094d1-81f2-4fbd-b6d7-70d4942cd135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.modeling_electra.ElectraModel'>\n",
      "<class 'transformers.tokenization_electra.ElectraTokenizer'>\n"
     ]
    }
   ],
   "source": [
    "print(type(model))\n",
    "print(type(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a809b5c-ed9a-4023-88c3-8ea0a2400787",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"오늘은 불금이지만 난 집에 박혀 코딩을 하고 있다\"\n",
    "sentence2 = \"그래도 난 행복해 길게 길게 길게 만들자\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed292897-89f8-4dea-a66a-e18983d980f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\n",
    "            sentence1, sentence2,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            max_length=50,\n",
    "            pad_to_max_length=True,\n",
    "            add_special_tokens=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03c4bab3-7a55-4d70-b2fb-f95cbb1ca6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2,  6451,  4112, 27123,  6965,  4172,  2239,  3354,  4073, 19556,\n",
       "         26843,  4292, 14227,  3249,  4176,     3,  7505,  2239,  7003,  4151,\n",
       "          2139,  4325,  2139,  4325,  2139,  4325,  6284,  4195,     3,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6344c781-d2a8-4e56-99ea-b7d3505cfb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,  6451,  4112, 27123,  6965,  4172,  2239,  3354,  4073, 19556,\n",
       "         26843,  4292, 14227,  3249,  4176,     3,  7505,  2239,  7003,  4151,\n",
       "          2139,  4325,  2139,  4325,  2139,  4325,  6284,  4195,     3,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'] # 모델의 input이 되는 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f687e64-06b8-427b-9d1d-e97cc1d5ffa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['token_type_ids'] # 문장을 구분짓는 id -> 한 문장인 경우 다 0, 두 문장인 경우 0과 1로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60451791-916f-4732-a4a6-3c1520eeb25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['attention_mask'] # padding을 구분짓는 변수 -> 0이면 padding 1이면 글자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4143eb02-bd28-4157-b77c-0f59e5acffb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['오늘', '##은', '불금', '##이지', '##만', '난', '집', '##에', '박혀', '코딩', '##을', '하고', '있', '##다']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.tokenize(sentence1)) # 입력된 문장은 토큰화된 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c6c944b-3c92-4599-b7d6-721bc7a93598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 6451, 4112, 27123, 6965, 4172, 2239, 3354, 4073, 19556, 26843, 4292, 14227, 3249, 4176, 3]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(sentence1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e974186-dcba-4ae0-b0de-7b9e8fb8812f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 오늘은 불금이지만 난 집에 박혀 코딩을 하고 있다 [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenizer.encode(sentence1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501a61f4-6cf8-4686-997d-39103c83ee60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
